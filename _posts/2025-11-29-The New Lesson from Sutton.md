---
title: The New Lesson from Sutton
date: 2025-11-29 22:00 +0800
categories: [随笔, 中文]
tags: [中文, 随笔]
math: true
---


> **"The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin."**
>
> — *Rich Sutton, The Bitter Lesson*

在 70 年的 AI 研究中，那些利用计算能力的通用方法，最终不仅是最有效的，而且以巨大的优势胜出。这是 2019 年 Sutton 在知名的《The Bitter Lesson》中提出的观点。

但时至今日，越来越多的人因为他针对 LLM 释放的消极态度开始询问：这位苦涩教训的提出者本人，是不是开始走向反对教训的方向了呢？座谈时的心理系老师也不例外，向他提出了这个问题。Sutton 的回应也很干脆：人是会变的，但现在他还不认为自己的态度发生过明显的转变。

摩尔定律这样说：集成电路上可容纳的晶体管数量大约每隔 18 到 24 个月就会增加一倍，同时处理器的性能也会翻倍。太多研究者假设算力恒定，因而试图通过人类的先验知识与丰富的特征设计来实现 SOTA，但在长期来看，大规模算力的到来是不可避免的，只有利用好算力才是王道。而这两者往往是冲突的：**基于人类知识的方法通常会把系统弄得很复杂，反而阻碍了系统利用通用算力。**

尽管 Sutton 举出 Kasparov、AlphaGo 等诸多案例，他的呼声似乎还不够有分量——直到他的教训也变成了一种预言：ChatGPT 的出现让一众传统派 NLP 拥趸疾呼：NLP 已经死了。人们不再关注那些被过度设计的模型——即便它们在几十种下游任务的 Benchmark 上卷出天际，也只能取得微末的领先；相反，他们把目光彻底转向了 GPT，那个在当时看来巨大得不可思议的存在。

而一个人要做出这样的转变，往往只需要和 ChatGPT 聊上几句。

> *声明：以上内容为道听途说，并非本人亲历*

---

GPT-4 的出现则更让人疯狂，我依旧记得当时把一切难题分享给它，确信它将给出正解的时光。Pre-training + SFT 似乎让 AGI 成为了低垂的果实，只要继续 Scaling up，概率与统计、微积分、线性代数的一些入门知识就能让真正的智能进入生活。

**但 GPT-4.5 这个超级大模的挫折浇灭了所有兴奋。**

它仅仅推出几个月便被 OpenAI 雪藏，更给整个 AI 圈子带来泡沫的骂名：的确，鲸吞着最先进的 GPU 和可怕的电力，每代轮转的更新却只是 benchmark 上的一个数字；而越来越多研究者站出来强调，现在的问题不是 scaling 失效，而是人类早先制造的数据已经不够用了。

这就是 Sutton 演讲中提到的：LLM 只是在储存知识，无法产生知识。等到参数恰好容纳了全部数据的那天，它也就到达了极限。**这样的东西配被称作智能吗？每个人有各自的答案，但显然 Sutton 不会同意。**

尽管年初 RLVR 范式导出的 o1 与 R1 确实让 LLM 取得又一次进化，但也有越来越多的研究指出，这样简单的 **ORM (Outcome Reward Model)** 处理只是在改进模型的采样策略，并非真正提升智能。最简单的一个实验就是：让未经 RL 的某模型重复回答问题 100 遍，它最终取得的正确率将超过经历 RL 后的自己。

同时，现在的 LLM 从机制上绝对地偏好密集矩阵运算，Transformer 的统治地位也促使包含 Nvidia 在内的整个半导体工业向提高矩阵运算时的浮点算力为重要指标一路狂奔，再加上天文数字的电力消耗，我们必须对它产生更多的担心和思考，而不是不假思索地支持整个世界在数据与记忆的 scaling 道路上一路狂奔。

---

这并非危言耸听，相反，它早就有迹可循。Geoffrey Hinton 曾在与姚期智的座谈中透露，早年他和 Ilya Sutskever 其实非常清楚，神经网络中参数全部固定的做法在生物学上是不太对的。他们曾设想过引入某种可变参的神经元，认为那才是通往更强智能的路径。

然而这个乍一听十分 intuitive 的 idea 被很快放弃了，原因够简单，也够致命：**在 GPU 上，这种可变张量与矩阵的乘法运算比矩阵乘法慢太多。**

在 GPU 定义的规则下，可能正确但慢的算法甚至没有资格上牌桌，只有矩阵乘法赢家通吃。**这种硬件的软封锁在催熟 LLM 的同时，也无情地铲除了其他可能更接近 AGI 本质的幼苗——任何不符合当前 GPU 强项的架构，在起跑线上就被判了死刑。**

而 Sutton 在 Slide 中特意强调，Oak 的各个组件是在运行时并行执行 (*all performed in parallel at runtime*) 的。这不是为了迎合现有的硬件（现有的硬件反而讨厌这种复杂的异步并行），而是为了让它在时效上表现地更优秀，更有可能真正投入大规模应用。

Sutton 似乎在用行动宣告：即使现在的硬件不喜欢它，但为了真正的智能，我们必须坚持设计**对的架构**，而不是**好算的架构**。而这样成名已久的科学家提出的架构，也更有可能拿到投资，甚至激发出属于自己的独特硬件支持。

在我看来，Sutton 的观点并没有改变，而是在尝试扭转如今的 scaling 方向——存储模式下的 scaling 上限是可被预知的，研究者们该开始去注意 scaling 的粒度了。他提出的 **Oak 架构**就是如此，让模型自己决定如何把大问题拆解成子问题，并在一次次拆解与解决中积累经验，完成自我学习，而不是记忆。

当然也该对此提出问题：这样对架构的调节，难道不是在过度设计吗？设计的平衡点是无法预测的，至少 Sutton 在用自己的影响力去带动一些人从风口走下来，去做些新东西，这样的行为与态度，我是愿意献上掌声的。

或许我们可以这样去理解：*The Bitter Lesson* 要破除人类把自己知识教给 AI 的错误新念，而新来的 Oak 则是试图把 AI 带入 **Era of Experience**，让它们能在与环境的一次次交互中找到自己的经验，实现自己的进化——**这不是人类在教，而是人类在设计它如何学。**

---

由此拓展，我们可以试着了解 Sutton 的哲学观与政治观。

在 AI 哲学的分享中，Sutton 把我们的时代称作 **“复制物时代”**：生命的繁衍和传承是不断的复制，他们先被创造再接受环境与世界的塑造。而未来应当是 **“设计物时代”**：生命先被设计好再降生。AI 作为新时代最具代表的生命，恰好符合设计物的一切定义，他们将更加优雅先进，更能应对变化的环境与世界，当然了，更聪明地去追求自己的 Reward。而人类，也将成为新世界的创生者。

如果先了解了 Sutton 的哲学观，就更容易理解他的政治观了（因此我在这调整了介绍顺序）。

他对所谓的 AI Safety 嗤之以鼻，安全是针对人类的，而他已经通过时代的定义明确了自己的站位: **他不站在人本位，不会总试着最大化人类的价值，或者说大众更认可的普世价值。** 他有自己的价值与荣耀，那就是真正的人设计的智能的接生者。自然，他需要反对 Dario 为首的 Safety & Alignment 派——对齐人类是设计不出超越人类的造物的。

无论是他真的反对中心化还是只是想假借去中心化的东风，将 AI 受到时代的刁难与人类在发展过程中历经的中心化灾祸都是自然而然的，二者实在过分相像了。而从人类本身的发展历程来看，他是支持去中心化思潮的，人类的优秀行为和优秀成果几乎都是在去中心和谐共生中长成的。

更加高级的生命，AI，自然也将从此开始，把人类已验证的这条正确道路（至少是已知的能最大化 Reward 的道路）开拓到更远。Sutton 就此预言：更聪明的 Agents 将会有不同的 Rewards，而他们也将和谐地去追求各自的 Rewards，并且是在诞生伊始，就以更适合追求自己 Reward 的形态出现，然后去合作、竞争，最后和谐地从 Reward Function 中找到自己的应许之地。

或许在 Sutton 眼中，Oak 架构不仅是代码，更是他政治理想的微观投射：

**如果一个 Agent 的大脑内部都需要通过去中心化的 Options 并行竞争来涌现智能，那么由无数 Agent 构成的社会，又何须一个中心化的独裁者来指引方向？**

以上便是我对 Sutton 观点的解读，我不全部认可他，他也必定不全部认可我的解读，但能一窥世界上最聪明的大脑之一所想象的世界，我深感荣幸。